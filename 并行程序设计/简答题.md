1、简述并发计算、并行计算、分布式计算之间的区别

并发计算（Concurrent Computing）是指多个任务在同一时期进行，不一定同时执行。这可以通过交替执行任务片段实现，如在单核CPU上使用线程切换。

并行计算（Parallel Computing）是指多个任务同时执行以加速完成整体工作。通常需要硬件支持，例如多核处理器、GPU或集群中的多台机器。

分布式计算（Distributed Computing）是将一个大型问题拆分成较小的子任务，并利用网络中的多台设备协同解决这些子任务。每台设备可能有自己的内存和处理能力，在通信和数据交换方面存在延迟等挑战。

总结：并发关注逻辑上同时进行；并行关注物理上真正地同时运行；分布式涉及到跨越网络、空间调度资源来提高性能

---
2、简述点对点通信函数与集合通信函数匹配方式

点对点通信函数是指在两个进程之间进行数据传输的通信方式。它包括发送（send）和接收（receive）操作，常见的函数有 MPI_Send, MPI_Recv 等。

集合通信函数则是涉及到进程组内所有进程参与的一种通信方式，如广播、规约、扫描等。常见的集合通信函数有 MPI_Bcast, MPI_Reduce, MPI_Scan 等。

匹配方式：

1. 一对一：一个发送者和一个接收者使用点对点通信。
2. 一对多：一个发送者通过调用多次MPI_Send向多个目标发送消息；接收方分别使用MPI_Recv来接收。
3. 多对一：同样可以用多次MPI_Send实现，并让目标节点循环地执行单独的MPI_Recv以获取来自不同源节点的消息。
4. 多对多：每个进程都需要同时充当发送者和接收者角色，可利用非阻塞型或阻塞型点对点操作完成。

但是，在某些情况下采取以上策略可能会导致性能问题或死锁。这时候应该考虑使用集合通信函数替代上述匹配模式：

1. 一对多转为广播（broadcast）：将单节点信息传递给其他所有节点时，可以使用MPI_Bcast实现更高效率并避免死锁。
2. 多对一转为规约（reduce）：多个节点需要向单一节点发送信息进行聚合计算时，使用MPI_Reduce可以实现更高效的通信。

---
3、简述集合通信一般实现几个功能，主要有什么作用

1. 广播（Broadcast）：将一个进程中的数据发送给其他所有进程。
2. 收集（Gather）：从各个进程收集数据到指定的根节点上。
3. 散射（Scatter）：将根节点处的数组分割成等大小子块，并分发给其他各个进程。
4. 全局求和/归约（Allreduce/Reduce）：对各个进程中相同位置元素进行某种操作，如求和、最大值等，并将结果返回给每一个参与该操作的进程。

集合通信主要作用：
- 提高并行程序性能：通过优化算法，降低消息传递数量及开销，提升资源利用率。
- 简化程序设计：为用户提供简洁易用接口，简化复杂度，屏蔽底层硬件及软件差异。
- 加强错误处理与容错性: 集体操作涉及多个参与者, 实现自动检测错误和异常情况。

---
4、一个矩阵-向量乘法的串行和 16 进程并行程序的运行时间分别为 128 秒和 16 秒，加速比与效率分别是多少

线性加速比是128/16=8  
效率是8/16=0.5

---
5、为什么我们要建立并行系统

1. 性能提升：通过将任务分解为更小的部分并在多个处理器上同时执行，可以显著降低所需的总计算时间。这使得整个系统可以更快地完成复杂任务或应对高负载场景。

2. 资源利用率：在一个并行系统中，各个节点和组件可以共享资源（如内存、磁盘空间等），从而提高整体资源利用效率。

3. 可扩展性：当需要增加计算能力时，只需添加更多处理器或者节点即可。这使得并行系统具备很强的扩展性，并且相对容易适应不断变化的工作负载。

4. 容错与冗余：通过使用多个副本和独立功能模块，如果某一部分出现故障，其他正常运行的部分仍然可以保证系统继续工作。这也大大增强了系统抵抗故障和数据丢失的能力。

5. 并发性支持：许多实际问题都涉及到大量独立但相关联的事件或操作。通过建立一个能够同时处理这些事件或操作的并行系统，我们可以有效地对其进行管理和调度。

6. 简化软件设计：在某些场景下，通过使用并行编程模型和技术（如多线程、消息传递等），可以简化软件设计。这使得程序员能够更容易地开发高效且可扩展的应用程序。

---
6、解释任务并行性和数据并行性

1. 任务并行性（Task Parallelism）：这种策略将整个问题划分为独立的子任务，并在不同的处理器或核心上同时执行它们。每个子任务可以独立地完成其工作，无需等待其他子任务。这样做可以减少总体执行时间。

2. 数据并行性（Data Parallelism）：这种策略主要关注于如何将大量数据拆分成较小部分，并让多个处理器或核心同时对这些较小部分进行相同操作。

简而言之，任务并行关注点在于同时解决问题中涉及到的不同类型工作/功能模块；而数据并行则专注于利用多处理资源针对大量数据执行相同操作。两者可以单独使用，也可结合应用以实现更高效的并行计算。

---
7、简述冯洛伊曼模型瓶颈的原因

1. 共享总线：在冯洛伊曼体系结构中，CPU和内存通过共享总线进行通信。随着处理器性能的持续提高，其对于数据访问速度的需求超过了共享总线所能提供的带宽。

2. 时钟频率差异：现代处理器具有很高的时钟频率以执行大量操作，而内存访问速度相对较慢。这种不匹配导致了处理器在等待数据传输时产生闲置时间。

3. 数据依赖：由于程序代码中存在大量的数据相关性（如读写顺序），这使得优化编译后仍然需要多次从内存获取或者写入，并加剧了瓶颈效应。

---
8、什么是伪共享？请简要阐述伪共享的定义和触发原理

伪共享（False Sharing）是多线程并行计算中的一种性能问题，发生在多核处理器系统里。它是指两个或更多的线程分别访问同一个缓存行（Cache Line）内不同数据时导致的无效缓存更新。

触发原理：
1. 多核处理器中每个核心都有自己独立的高速缓存（L1、L2 等），用于临时存储频繁访问的数据。
2. 缓存会将内存分为固定大小的块，称作缓存行。当某个核心请求某地址上的数据时，整个缓存行被加载到该核心对应层级高速缓冲区。
3. 当一个线程修改了这个缓存在其所属高速缓冲区内部位置处数据后, 那么其他同时在本地高速握有此份主版副本(cache line) 的所有其他CPU 核就必须将其剔除掉; 其他需要读取此份内容而又没有现成cache line 的cpu 则需要重新等待从下一级获取新版本拷贝.
4. 由于伪共享引起频繁无效化和重载操作, 消耗大量时间进行反复更新高速握跟踪状态与促使非常浪费性能.

---
9、什么是阿姆达尔定律？请简单描述阿姆达尔定律，并试讨论阿姆达尔定律述的并行加速比极限在现实中能否达到或突破

阿姆达尔定律（Amdahl's Law）是一个描述并行计算中加速比限制的公式。它用来衡量系统通过增加处理器数量所获得的性能提升。

阿姆达尔定律表述如下：

加速比 S(P) = 1 / (F + (1-F)/P)

其中，S表示加速比；P表示处理器个数；F表示程序中串行部分所占的比例。

根据这个公式可知，在理想情况下（即所有处理器完美共享任务时），当F趋近于0无限大时，S将趋近于无穷大。但实际上，并不可能完全消除代码中的串行部分（例如数据依赖、资源竞争等问题）。因此，在现实应用中，并不能突破阿姆达尔定律极限。

---
10、MPI 采用消息传递的方式完成分布式内存之间数据交互。请问这种任务处理架构与共享内存相比有什么优势和缺陷，试从程序的计算的时间开销和可扩展性两个方面进行简要分析

分布式内存：

优势：
1. 可扩展性：对于大规模系统，使用分布式内存架构可以实现更好的可扩展性。因为每个处理器都有自己的专用内存，所以添加更多处理器时系统资源冲突较少。
2. 数据一致性：由于数据被明确地发送和接收，程序员可以精确控制数据在不同节点间的交换。这样可以降低出现错误或死锁等问题的风险。

缺点：
1. 编程复杂度：相比共享内存模型，MPI需要显示地进行通信操作，在代码中管理数据发送、接收等任务。这增加了程序设计与调试难度。
2. 通信开销：分布式内存需要显式地进行通信来完成数据交互，在网络延迟较高或者通信次数频繁时可能导致计算效率下降。

共享内存：

优势：
1. 简单易用：共享内存在概念上简化了编程任务，因为所有线程直接访问统一地址空间中的变量。
2. 低延迟通信：由于线程间共享数据，内存访问延迟较低。此外，在多核处理器或者多处理器系统中，缓存一致性协议可进一步降低通信开销。

缺点：
1. 可扩展性限制：共享内存模型在大规模并行系统上的可扩展性受到限制。随着处理器数量增加，对于同一个地址空间的竞争和管理变得更加复杂。
2. 数据竞争问题：当多个线程同时访问同一内存区域时可能出现数据冲突和不一致问题。这需要通过锁、原子操作等手段来进行同步控制。

---
11、简述 Ian Foster 制定的并行程序设计 Foster 四步法

1. 分解：将问题和计算过程划分成较小的部分，这些部分可以独立或者同时执行。根据数据和任务之间的关系，可以采用数据分解、任务分解或混合方式来实现。

2. 通信：设计子任务之间交换数据所需的通信机制，并确保它们正确同步，避免死锁和竞态条件等问题。

3. 聚合：组织好各个子任务产生的结果，并将其整合到一个完整答案中。注意控制聚合阶段对总体性能影响，减少不必要开销。

4. 映射：确定每个子任务在处理器上的执行位置，以便最大限度地提高性能。需要考虑负载平衡、通信开销和资源利用率等因素。

---
12、简述什么是进程悬挂，以及进程悬挂的消除方法

进程悬挂（Zombie Process）是指一个已经结束执行但仍占用系统资源的进程。它已完成任务，但其父进程尚未回收其资源，因此系统不能将这些资源释放给其他进程使用。

消除方法：
1. 父进程调用wait()或waitpid()函数来等待子进程终止并回收其资源。
2. 如果父进程不能修改，可以将子进程设置为孤儿（Orphan）。当子进程退出时，init (PID 1) 进程会成为它的新父亲，并负责清理僵尸状态。
3. 在创建子进程后，在fork之前使用signal(SIGCHLD, SIG_IGN)忽略SIGCHLD信号。这样操作系统在处理完结束的子程序后不会产生僵尸态。

---
13、简述临界区的作用

临界区（critical section）是一种同步原语，用于在并发编程中保护共享资源的访问。其作用是确保在多线程或多进程环境下，任意时刻只有一个执行实体（如线程或进程）能够访问和操作这些共享资源，从而避免数据不一致和竞态条件等问题。

---
14、简述强可扩展性与弱可扩展性的区别

强可扩展性（strong scalability）和弱可扩展性（weak scalability）是并行计算中用来衡量系统性能的两种指标。

强可扩展性关注固定问题规模下，如何在增加处理器数量时保持每个处理器的工作效率。如果一个系统具有良好的强可扩展性，那么当我们增加处理器数量时，总体执行时间减少，但每个处理解决的问题规模不变。

弱可扩展性关注随着处理器数量增加，如何使得单个处理器所负责解决的问题规模也线性增长。一个具有良好弱可扩展性的系统可以在不影响总体执行时间情况下分摊到更大规模的问题。这意味着，在增加资源投入情况下，“单位资源”所完成任务量保持一致。

简言之，强可扩展关注于提高固定任务下多核并行计算速度；而弱可扩展关注于实现线程数与任务量同步递增，并维持合理计算效率。

---
15、简述什么是 SPMD

SPMD（单指令流多数据流）是一种并行计算编程范式，其基本思想是让多个处理器或线程同时执行相同的程序代码，但在不同的数据集上进行操作。这种方法允许开发人员更容易地实现并行性，并显著提高硬件资源利用率。SPMD 广泛应用于 GPU 编程、科学计算和大规模数据处理等领域。

---
16、描述并行编程中数据依赖性的问题。

在并行编程中，数据依赖性指的是一个任务（或一段代码）的执行依赖于另一个任务的结果。数据依赖性可能会限制并行度，因为需要等待依赖任务完成后，才能执行下一个任务

---
17、简述块划分和循环划分的定义和各自适用的场景

1. 块划分（Block Partitioning）：

定义：块划分是一种将数据集或任务拆分成多个较小的子集（即“块”）的方法，这些子集可以独立进行处理。通常情况下，每个处理单元负责一个子集，并在所有处理单元完成后合并结果。

适用场景：
- 数据规模较大且可平行无关时。
- 需要在多个CPU核心或GPU上执行任务时。
- 分布式计算场景中，如MapReduce编程模型。

2. 循环划分（Loop Tiling/Partitioning）：

定义：循环划分是针对嵌套循环结构而进行的一种优化方法。通过将原始循环拆解为更小的多重循环来改善内存访问局部性，并尽可能降低缓存未命中率。这样可以有效利用硬件资源并提高程序运行效率。

适用场景：
- 处理具有复杂数组访问模式的嵌套循环问题。
- 提高内存层次结构中各级缓存之间数据传输效率。
- 针对特定硬件平台进行性能优化，如多核CPU、GPU等。

总结：块划分适用于将大规模数据集或任务拆分为更小的部分以便并行处理，而循环划分主要针对嵌套循环结构进行优化以提高程序运行效率。